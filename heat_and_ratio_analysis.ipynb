{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../traces/MSR-Cambridge2/CAMRESSDPA01-lvm0.csv', header=None)\n",
    "df.columns = ['Timestamp', 'Hostname', 'DiskNumber', 'Type', 'Offset', 'Size', 'ResponseTime']\n",
    "df['Timestamp'] = df['Timestamp'].astype(np.int64)\n",
    "df = df.sort_values(by='Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pool_size = df.drop_duplicates(['Offset'])['Size'].sum()\n",
    "total_request_byte = df['Size'].sum()\n",
    "total_request_count = df.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_requests():\n",
    "    for row in df.itertuples():\n",
    "        yield getattr(row, 'Offset'), getattr(row, 'Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server:  # 服务器(cache)\n",
    "    def __init__(self, space):\n",
    "        self.space = space  # cache大小\n",
    "        self.remain = space  # cache剩余空间\n",
    "        self.cache = OrderedDict()  # OrderDict() 模拟cache LRU方法\n",
    "        self.hit_count = 0  # 命中次数\n",
    "        self.hit_byte = 0\n",
    "        self.miss_count = 0  # 未命中次数\n",
    "        self.miss_byte = 0\n",
    "\n",
    "    def _hit(self, fid, size):\n",
    "        self.hit_count += 1\n",
    "        self.hit_byte += size\n",
    "        self.cache.move_to_end(fid)\n",
    "\n",
    "    def _miss(self, fid, size):\n",
    "        self.miss_count += 1\n",
    "        self.miss_byte += size\n",
    "        while self.remain < size:\n",
    "            self.remain += self.cache.popitem(last=False)[-1]  # pop出第一个item\n",
    "        self.cache[fid] = size\n",
    "        self.remain -= size\n",
    "\n",
    "    def handle(self, fid, size):  # 处理一次请求\n",
    "        if fid in self.cache.keys():\n",
    "            self._hit(fid, size)\n",
    "        else:\n",
    "            self._miss(fid, size)\n",
    "\n",
    "    def hit_rate(self):\n",
    "        try:\n",
    "            return self.hit_count / (self.hit_count + self.miss_count)\n",
    "        except:\n",
    "            return \"Server has not been requested yet!\"\n",
    "\n",
    "    def byte_hit_rate(self):\n",
    "        try:\n",
    "            return self.hit_byte / (self.hit_byte + self.miss_byte)\n",
    "        except:\n",
    "            return \"Server has not been requested yet!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dispatcher1:\n",
    "    def __init__(self, cache_size, cache_number, simple=True):\n",
    "        self.cache_number = cache_number\n",
    "        self.big_cache = Server(cache_size * cache_number)\n",
    "        self.small_caches = []\n",
    "        for i in range(cache_number):\n",
    "            server = Server(cache_size)\n",
    "            self.small_caches.append(server)\n",
    "        self.small_caches_heat = [0] * cache_number\n",
    "        if simple:\n",
    "            self.handle_requests = self.simple_hash\n",
    "        else:\n",
    "            self.handle_requests = self.load_balance\n",
    "            self.file_mapper = {}\n",
    "            for row in df.drop_duplicates(['Offset']).itertuples():\n",
    "                fid = getattr(row, 'Offset')\n",
    "                self.file_mapper[fid] = (fid // 10000 % 1000000) & 0b11111 % cache_number\n",
    "\n",
    "    def load_balance(self, fid, size):\n",
    "        server = self.file_mapper[fid]\n",
    "        if fid in self.small_caches[server].cache.keys():\n",
    "            self.small_caches[server].handle(fid, size)\n",
    "            self.small_caches_heat[self.file_mapper[fid]] += size\n",
    "        else:\n",
    "            server = self.small_caches_heat.index(min(self.small_caches_heat))\n",
    "            self.small_caches[server].handle(fid, size)\n",
    "            self.file_mapper[fid] = server\n",
    "        self.big_cache.handle(fid, size)\n",
    "\n",
    "    def simple_hash(self, fid, size):\n",
    "        self.small_caches[(fid // 10000 % 1000000) & 0b11111 % self.cache_number].handle(fid, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dispatcher2:\n",
    "    def __init__(self, cache_size, cache_number, simple=True):\n",
    "        self.cache_number = cache_number\n",
    "        self.big_cache = Server(cache_size * cache_number)\n",
    "        self.small_caches = []\n",
    "        for i in range(cache_number):\n",
    "            server = Server(cache_size)\n",
    "            self.small_caches.append(server)\n",
    "        self.small_caches_heat = [0] * cache_number\n",
    "        if simple:\n",
    "            self.handle_requests = self.simple_hash\n",
    "        else:\n",
    "            self.handle_requests = self.load_balance\n",
    "            self.file_mapper = {}\n",
    "            for row in df.drop_duplicates(['Offset']).itertuples():\n",
    "                fid = getattr(row, 'Offset')\n",
    "                self.file_mapper[fid] = (fid // 10000 % 1000000) & 0b11111 % cache_number\n",
    "\n",
    "    def load_balance(self, fid, size):\n",
    "        server = self.file_mapper[fid]\n",
    "        if fid in self.small_caches[server].cache.keys():\n",
    "            self.small_caches[server].handle(fid, size)\n",
    "        else:\n",
    "            server = self.small_caches_heat.index(min(self.small_caches_heat))\n",
    "            self.small_caches[server].handle(fid, size)\n",
    "            self.file_mapper[fid] = server\n",
    "        self.small_caches_heat[server] += size\n",
    "        self.big_cache.handle(fid, size)\n",
    "\n",
    "    def simple_hash(self, fid, size):\n",
    "        self.small_caches[(fid // 10000 % 1000000) & 0b11111 % self.cache_number].handle(fid, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5659341\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "FILE_NUM = len(df['Offset'].value_counts())\n",
    "CACHE_NUMBER = 4\n",
    "print(FILE_NUM)\n",
    "print(CACHE_NUMBER)\n",
    "\n",
    "dispatcher1_small_server_hit_byte_ratio = []\n",
    "dispatcher2_small_server_hit_byte_ratio = []\n",
    "big_server_hit_byte_ratio = []\n",
    "heat1 = []\n",
    "heat2 = []\n",
    "hit_ratio1 = []\n",
    "hit_ratio2 = []\n",
    "hit_ratio_big = []\n",
    "small_hit_ratio1 = []\n",
    "small_hit_ratio2 = []\n",
    "time_array = []\n",
    "cache_size_array = []\n",
    "\n",
    "cache_size_range = [256000000, 512000000, 1024000000, 2048000000, 4096000000, 8192000000, 16384000000]\n",
    "\n",
    "small_cache_count_hit_ratio = []\n",
    "small_cache_byte_hit_ratio = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37415613it [05:17, 117812.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16042165it [02:23, 112111.57it/s]"
     ]
    }
   ],
   "source": [
    "for cache_size in cache_size_range:\n",
    "\n",
    "    print(cache_size)\n",
    "\n",
    "    cache_size_array.append(cache_size / 1000000)\n",
    "    dispatcher1 = Dispatcher1(cache_size, CACHE_NUMBER, False)\n",
    "    dispatcher2 = Dispatcher2(cache_size, CACHE_NUMBER, False)\n",
    "    time = 0\n",
    "    for fid, size in tqdm(make_requests()):\n",
    "        dispatcher1.handle_requests(fid, size)\n",
    "        dispatcher2.handle_requests(fid, size)\n",
    "        time += 1\n",
    "        if cache_size == 16384000000 and time % 100 == 0:\n",
    "            time_array.append(time)\n",
    "            heat1.append(dispatcher1.small_caches_heat)\n",
    "            heat2.append(dispatcher2.small_caches_heat)\n",
    "\n",
    "            hit_ratio_big.append(dispatcher1.big_cache.hit_byte / (dispatcher1.big_cache.hit_byte + dispatcher1.big_cache.miss_byte))\n",
    "            hit_ratio1.append(sum([i.hit_byte for i in dispatcher1.small_caches]) / (dispatcher1.big_cache.hit_byte + dispatcher1.big_cache.miss_byte))\n",
    "            hit_ratio2.append(sum([i.hit_byte for i in dispatcher2.small_caches]) / (dispatcher2.big_cache.hit_byte + dispatcher2.big_cache.miss_byte))\n",
    "            small_hit_ratio1.append([i.byte_hit_rate() for i in dispatcher1.small_caches])\n",
    "            small_hit_ratio2.append([i.byte_hit_rate() for i in dispatcher2.small_caches])\n",
    "\n",
    "    dispatcher1_small_server_hit_byte_ratio.append(sum([i.hit_byte for i in dispatcher1.small_caches]) / (dispatcher1.big_cache.hit_byte + dispatcher1.big_cache.miss_byte))\n",
    "    dispatcher2_small_server_hit_byte_ratio.append(sum([i.hit_byte for i in dispatcher2.small_caches]) / (dispatcher2.big_cache.hit_byte + dispatcher2.big_cache.miss_byte))\n",
    "    big_server_hit_byte_ratio.append(dispatcher1.big_cache.hit_byte / (dispatcher1.big_cache.hit_byte + dispatcher1.big_cache.miss_byte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看实时命中率\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(time_array, hit_ratio_big, color='black', label='big cache')\n",
    "plt.plot(time_array, hit_ratio1, color='red', label='dispatcher1')\n",
    "plt.plot(time_array, hit_ratio2, color='blue', label='dispatcher2')\n",
    "plt.xlabel(\"time(request num)\")\n",
    "plt.ylabel(\"byte hit ratio\")\n",
    "plt.title('real time hit ratio')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看命中率与cache大小的关系\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(cache_size_array, big_server_hit_byte_ratio, color='black', label='big cache')\n",
    "plt.plot(cache_size_array, dispatcher1_small_server_hit_byte_ratio, color='red', label='dispatcher1')\n",
    "plt.plot(cache_size_array, dispatcher2_small_server_hit_byte_ratio, color='blue', label='dispatcher2')\n",
    "plt.xlabel(\"small cache size / Mb\")\n",
    "plt.ylabel(\"byte hit ratio\")\n",
    "plt.title(\"hit ratio of different cache size\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'green', 'pink', 'brown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher1中小cache热度实时变化情况\n",
    "plt.figure(figsize=(15,8))\n",
    "for i in range(4):\n",
    "    plt.plot(time_array, [j[i] for j in heat1], color=colors[i], label='small cache'+str(i+1))\n",
    "plt.xlabel(\"time(request num)\")\n",
    "plt.ylabel(\"small cache's heat\")\n",
    "plt.title(\"dispatcher1's heat\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatcher2中小cache热度实时变化情况\n",
    "plt.figure(figsize=(15,8))\n",
    "for i in range(4):\n",
    "    plt.plot(time_array, [j[i] for j in heat2], color=colors[i], label='small cache'+str(i+1))\n",
    "plt.xlabel(\"time(request num)\")\n",
    "plt.ylabel(\"small cache's heat\")\n",
    "plt.title(\"dispatcher2's heat\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dispatcher1中小cache命中率实时变化情况\n",
    "plt.figure(figsize=(15,8))\n",
    "for i in range(4):\n",
    "    plt.plot(time_array, [j[i] for j in small_hit_ratio1], color=colors[i], label='small cache'+str(i+1))\n",
    "plt.xlabel(\"time(request num)\")\n",
    "plt.ylabel(\"small cache's hit ratio\")\n",
    "plt.title(\"dispatcher1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dispatcher2中小cache命中率实时变化情况\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(4):\n",
    "    plt.plot(time_array, [j[i] for j in small_hit_ratio2], color=colors[i], label='small cache'+str(i+1))\n",
    "plt.xlabel(\"time(request num)\")\n",
    "plt.ylabel(\"small cache's hit ratio\")\n",
    "plt.title(\"dispatcher2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
